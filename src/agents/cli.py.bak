import os
import argparse
import traceback
import asyncio
from pathlib import Path
from typing import List
from dotenv import load_dotenv

from .agent import create_react_agent
from .codact_agent import create_codact_agent

try:
    from rich.console import Console
    from rich.markdown import Markdown
    from rich.panel import Panel
    from rich.live import Live
    from rich.status import Status
    from prompt_toolkit import PromptSession
    from prompt_toolkit.history import FileHistory

except ImportError as e:
    error_message = (
        f"Error: Required CLI dependencies are missing ({e}).\n"
        "Please install them using:\n"
        'uv pip install "DeepSearch-AgentTeam[cli]"\n'
    )
    print(error_message)
    exit(1)

load_dotenv()


# --- CLI Helper Functions ---

def display_welcome(args, console: Console):
    """
    Display welcome information
    """
    readme_path = 'README.md'
    description = ""
    try:
        with open(readme_path, "r") as f:
            readme_content = f.read()
        # æ›´å¥å£®åœ°æŸ¥æ‰¾æè¿°éƒ¨åˆ†
        description_match = readme_content.split("## 1. Introduction")
        if len(description_match) > 1:
            description_content = description_match[1].split("##")[0].strip()
            description = description_content if description_content else ""
        else:
            description_section = readme_content.split("## Description")
            if len(description_section) > 1:
                description_content = description_section[1].split("##")[0].strip()
                description = description_content if description_content else ""

    except FileNotFoundError:
        console.print(
            f"[yellow]è­¦å‘Š:[/yellow] æœªåœ¨é¢„æœŸä½ç½®æ‰¾åˆ° README.md: {readme_path}"
        )
    except Exception as e:
        console.print(f"[yellow]è­¦å‘Š:[/yellow] æ— æ³•è¯»å–æˆ–è§£æ README.md: {e}")

    console.print(Panel(
        Markdown(description) if description else
        "DeepSearchAgent (ReAct-CodeAct æ·±åº¦æœç´¢æ™ºèƒ½ä½“) "
        "æ˜¯ä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œè¿­ä»£å¼ç½‘é¡µæ·±åº¦æœç´¢å’Œæ·±åº¦ç ”ç©¶çš„ AI æ™ºèƒ½ä½“å›¢é˜Ÿã€‚",
        title="[bold cyan]DeepSearchAgent React ğŸš€[/bold cyan]",
        border_style="cyan",
    ))

    config_text = (
        f"ä»£ç†ç±»å‹: [bold cyan]{args.agent_type.upper()}[/bold cyan]\n"
        f"æœç´¢æ¨¡å‹: [cyan]{args.model_name}[/cyan]\n"
        f"åè°ƒæ¨¡å‹: [cyan]{args.orchestrator_model}[/cyan]\n"
        f"é‡æ’åºå™¨: [cyan]{args.reranker}[/cyan]\n"
        f"æœç´¢ç»“æœæ•°é‡: [cyan]{args.max_sources}[/cyan]\n"
        f"è¯¦ç»†æ¨¡å¼ (å·¥å…·æ—¥å¿—): [cyan]{'å¼€å¯' if args.verbose else 'å…³é—­'}[/cyan]"
    )

    # æ ¹æ®agent_typeæ˜¾ç¤ºç‰¹å®šçš„æ¨¡å¼ä¿¡æ¯
    if args.agent_type == "codact":
        config_text += f"\næ‰§è¡Œå™¨ç±»å‹: [cyan]{args.executor_type}[/cyan]\n" + \
                      f"æœ€å¤§æ­¥éª¤æ•°: [cyan]{args.max_steps}[/cyan]"

    console.print(Panel(
        config_text,
        title="[bold blue]é…ç½®ä¿¡æ¯[/bold blue]",
        border_style="blue",
    ))

    console.print("\n[dim]æç¤ºï¼šè¾“å…¥ /exit æˆ– /quit é€€å‡ºã€‚è¾“å…¥ /multiline åˆ‡æ¢ã€‚[/dim]")
    console.print("[bold]ç¤ºä¾‹æŸ¥è¯¢ï¼š[/bold]")
    console.print(
        "  â€¢ æœç´¢ Google OpenAI å’Œ Anthropic æœ€æ–°ä¸€å‘¨å‘å¸ƒçš„æ‰€æœ‰æ–°äº§å“," +
        "LLMæ¨¡å‹,æŠ€æœ¯,è®ºæ–‡,æœç´¢&åˆ†æåæ€»ç»“ç»™æˆ‘ã€‚"
    )
    console.print("  â€¢ æœç´¢å¹¶æ€»ç»“è¿‡å»ä¸€å‘¨å…³äºè¯­è¨€æ¨¡å‹ (LLM) çš„é‡è¦ç§‘æŠ€æ–°é—»ã€‚")


def handle_slash_command(
    command: str,
    multiline: bool,
    console: Console
) -> tuple[int | None, bool]:
    """å¤„ç†æ–œæ å‘½ä»¤"""
    if command in ('/exit', '/quit'):
        console.print("[dim]æ­£åœ¨é€€å‡º...[/dim]")
        return 0, multiline
    elif command == '/multiline':
        multiline = not multiline
        if multiline:
            console.print(
                '[cyan]å·²å¯ç”¨å¤šè¡Œæ¨¡å¼ã€‚[/cyan] [dim]æŒ‰ Esc+Enter æˆ– '
                'Ctrl+D (Unix) / Ctrl+Z+Enter (Win) æäº¤ã€‚[/dim]'
            )
        else:
            console.print('[cyan]å·²ç¦ç”¨å¤šè¡Œæ¨¡å¼ã€‚[/cyan]')
        return None, multiline
    # Add other commands like /markdown if needed
    # elif command == '/markdown':
    #     # ... (implementation to show last response markdown)
    #     pass
    else:
        console.print(f'[red]æœªçŸ¥å‘½ä»¤:[/red] {command}')
        return None, multiline


async def process_query_async(
    query: str,
    agent_instance,
    verbose_mode: bool,
    console: Console,
    last_response_md: List[str]  # Use list to pass by reference
):
    """
    å¼‚æ­¥å¤„ç†æŸ¥è¯¢å¹¶æ˜¾ç¤ºç»“æœ
    """
    status = Status("[cyan]Thinking...[/cyan]", console=console)
    live_params = {
        "console": console,
        "refresh_per_second": 10,
        "vertical_overflow": "visible"
    }
    live = Live(status, **live_params)
    last_response_md.clear()  # Clear previous response

    try:
        with live:
            # Use run_in_executor for the blocking agent.run call
            loop = asyncio.get_running_loop()
            result_str = await loop.run_in_executor(
                None, agent_instance.run, query
            )

        last_response_md.append(result_str)

        console.print("\n[bold green]å›ç­”:[/bold green]")
        console.print(Panel(
            Markdown(result_str),
            title="æœ€ç»ˆå›ç­”",
            border_style="green"
        ))

    except Exception:
        # Ensure live display stops before printing error
        live.stop()
        console.print(f"[bold red]å¤„ç†æŸ¥è¯¢ ' {query[:50]}...' æ—¶å‡ºé”™:[/bold red]")
        console.print(traceback.format_exc())  # More detailed traceback
    finally:
        if live.is_started:
            live.stop()


async def run_interactive_cli(
    agent_instance,
    args: argparse.Namespace,
    console: Console
):
    """
    è¿è¡Œäº¤äº’å¼ CLI å¾ªç¯
    """
    history_path = Path.home() / ".deepsearch-agent-history.txt"
    session = PromptSession(history=FileHistory(str(history_path)))
    multiline = False
    last_response_md: List[str] = []  # To store the last response

    while True:
        try:
            # auto_suggest = AutoSuggestFromHistory() # Add suggestions
            prompt_text = "DeepSearchAgent â¤ "
            text = await session.prompt_async(prompt_text, multiline=multiline)

        except (KeyboardInterrupt, EOFError):
            console.print("[dim]æ”¶åˆ°é€€å‡ºã€‚[/dim]")
            break

        if not text.strip():
            continue

        command = text.strip()
        if command.startswith('/'):
            exit_code, multiline = handle_slash_command(
                command, multiline, console
            )
            if exit_code is not None:
                break  # Exit loop if exit code is returned
        else:
            await process_query_async(
                text, agent_instance, args.verbose, console, last_response_md
            )
    return 0  # Indicate normal exit


def select_agent_type(console: Console) -> str:
    """äº¤äº’å¼é€‰æ‹©ä»£ç†ç±»å‹"""
    console.print(Panel(
        "è¯·é€‰æ‹©è¦ä½¿ç”¨çš„ä»£ç†ç±»å‹:\n\n" +
        "[1] [cyan]React[/cyan] - æ ‡å‡†ä»£ç† (JSONå·¥å…·è°ƒç”¨æ¨¡å¼)\n" +
        "    é€‚åˆç®€å•æŸ¥è¯¢ï¼Œæ¯æ¬¡å·¥å…·è°ƒç”¨åä¼šæ€è€ƒä¸‹ä¸€æ­¥æ“ä½œ\n\n" +
        "[2] [cyan]CodeAct[/cyan] - æ·±åº¦æœç´¢ä»£ç† (Pythonä»£ç æ‰§è¡Œæ¨¡å¼)\n" +
        "    é€‚åˆå¤æ‚æŸ¥è¯¢ï¼Œå¯ä»¥ç¼–å†™Pythonä»£ç å®ç°æ›´çµæ´»çš„æœç´¢ç­–ç•¥",
        title="[bold blue]ä»£ç†ç±»å‹é€‰æ‹©[/bold blue]",
        border_style="blue",
    ))

    while True:
        choice = input("è¯·è¾“å…¥é€‰é¡¹ç¼–å· [1/2]: ").strip()
        if choice == "1":
            return "react"
        elif choice == "2":
            return "codact"
        else:
            console.print("[red]æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1æˆ–2[/red]")


# --- ä¸»æ¥å£ --- #

def main():
    """
    CLI ä¸»å…¥å£ç‚¹
    """
    console = Console()

    parser = argparse.ArgumentParser(
        description=(
            'è¿è¡Œ DeepSearch-AgentTeam ReAct-CodeAct æ·±åº¦æœç´¢æ™ºèƒ½ä½“ '
            '(è¿­ä»£æœç´¢æ¨¡å¼) CLI'
        )
    )
    parser.add_argument(
        '--orchestrator-model',
        default=os.getenv(
            "LITELLM_ORCHESTRATOR_MODEL_ID",
            "openai/openrouter/openai/o4-mini-high"
        ),
        help='ç¼–æ’ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹åç§° (ä¾‹å¦‚ LiteLLM å…¼å®¹ ID)'
    )
    parser.add_argument(
        '--model-name',
        default=os.getenv(
            "LITELLM_SEARCH_MODEL_ID",
            "openai/openrouter/openai/o4-mini-high"
        ),
        help='æœç´¢æ¨¡å‹åç§° (ä¸»è¦ç”± Agent å†…éƒ¨å·¥å…·å†³å®šï¼Œæ­¤å¤„å¯èƒ½ä»…ç”¨äºæ˜¾ç¤º)'
    )
    parser.add_argument(
        '--reranker',
        default=os.getenv(
            "RERANKER_TYPE", "jina-reranker-m0"
        ),
        help="é‡æ’åºå™¨ç±»å‹ (ä¾‹å¦‚ 'jina-reranker-m0')"
    )
    parser.add_argument(
        '--max-sources',
        type=int,
        default=int(os.getenv("MAX_SOURCES", 5)),
        help='æœç´¢ç»“æœæ•°é‡ (å½±å“ SearchLinksTool)'
    )
    parser.add_argument(
        '--pro-mode',
        action='store_true',
        default=os.getenv("PRO_MODE", "False").lower() == 'true',
        help='æ˜¯å¦å¯ç”¨ä¸“ä¸šæ¨¡å¼ (å½“å‰æœªç›´æ¥ä½¿ç”¨ï¼Œä½†ä¿ç•™æ¥å£)'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        default=os.getenv("VERBOSE_TOOL_CALLBACKS", "True").lower() == 'true',
        help='æ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†è¿‡ç¨‹ (åŒ…æ‹¬å·¥å…·è°ƒç”¨æ—¥å¿—)'
    )
    parser.add_argument(
        '--query',
        type=str,
        help='ç›´æ¥è¿è¡Œå•ä¸ªæŸ¥è¯¢, è€Œä¸å¯åŠ¨äº¤äº’å¼CLI'
    )
    parser.add_argument(
        '--agent-type',
        choices=['react', 'codact'],
        default='react',
        help='é€‰æ‹©ä½¿ç”¨çš„ä»£ç†ç±»å‹: react (JSONå·¥å…·è°ƒç”¨) æˆ– codact (Pythonä»£ç æ‰§è¡Œ)'
    )
    parser.add_argument(
        '--executor-type',
        choices=['local', 'docker', 'e2b'],
        default='local',
        help='CodeActä»£ç†çš„ä»£ç æ‰§è¡Œå™¨ç±»å‹'
    )
    parser.add_argument(
        '--max-steps',
        type=int,
        default=30,
        help='ä»£ç†æ‰§è¡Œçš„æœ€å¤§æ­¥éª¤æ•°ï¼ˆCodeActæ¨èæ›´é«˜å€¼ï¼‰'
    )
    parser.add_argument(
        '--no-interactive',
        action='store_true',
        help='ç¦ç”¨äº¤äº’å¼é€‰æ‹©ä»£ç†ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨--agent-typeå‚æ•°'
    )

    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰ä½¿ç”¨--no-interactiveå‚æ•°ï¼Œå¹¶ä¸”æ²¡æœ‰æŒ‡å®šå•ä¸ªæŸ¥è¯¢ï¼Œåˆ™æä¾›äº¤äº’å¼é€‰æ‹©
    if not args.no_interactive and not args.query:
        # å¦‚æœå‘½ä»¤è¡Œæ²¡æœ‰æ˜ç¡®æŒ‡å®šä»£ç†ç±»å‹ï¼Œåˆ™è¿›è¡Œäº¤äº’å¼é€‰æ‹©
        if args.agent_type == parser.get_default('agent_type'):
            args.agent_type = select_agent_type(console)
            # æ›´æ–°æ˜¾ç¤ºï¼Œè®©ç”¨æˆ·çŸ¥é“é€‰æ‹©å·²ç”Ÿæ•ˆ
            console.print(
                f"[green]å·²é€‰æ‹©[/green]: "
                f"[cyan]{args.agent_type.upper()}[/cyan] ä»£ç†æ¨¡å¼"
            )

    # --- åˆ›å»ºä»£ç† --- #
    try:
        # Pass cli_console only if verbose is enabled
        cli_console_for_agent = console if args.verbose else None

        if args.agent_type == 'react':
            agent_instance = create_react_agent(
                orchestrator_model_id=args.orchestrator_model,
                search_model_name=args.model_name,
                reranker_type=args.reranker,
                verbose_tool_callbacks=args.verbose,
                cli_console=cli_console_for_agent,
            )
            if agent_instance is None:
                console.print(
                    "[bold red]é”™è¯¯:[/bold red] "
                    "æ— æ³•åˆå§‹åŒ– React Agentï¼Œå¯èƒ½ç¼ºå°‘å¿…è¦çš„ API å¯†é’¥ã€‚"
                )
                exit(1)
        else:  # codact
            agent_instance = create_codact_agent(
                orchestrator_model_id=args.orchestrator_model,
                search_model_name=args.model_name,
                reranker_type=args.reranker,
                verbose_tool_callbacks=args.verbose,
                cli_console=cli_console_for_agent,
                executor_type=args.executor_type,
                max_steps=args.max_steps,
                # è°ƒæ•´æ—¥å¿—çº§åˆ«: verbose -> INFO(1), not verbose -> WARNING(2)
                verbosity_level=1 if args.verbose else 2
            )
            if agent_instance is None:
                console.print(
                    "[bold red]é”™è¯¯:[/bold red] "
                    "æ— æ³•åˆå§‹åŒ– CodeAct Agentï¼Œå¯èƒ½ç¼ºå°‘å¿…è¦çš„ API å¯†é’¥ã€‚"
                )
                exit(1)

    except ValueError as e:
        console.print(f"[bold red]åˆå§‹åŒ– Agent æ—¶å‡ºé”™:[/bold red] {e}")
        exit(1)
    except Exception:
        console.print("[bold red]åˆ›å»º Agent æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯:[/bold red]")
        console.print(traceback.format_exc())
        exit(1)

    display_welcome(args, console)

    # --- è¿è¡Œæ¨¡å¼ --- #
    if args.query:
        console.print(f"[yellow]è¿è¡Œå•ä¸ªæŸ¥è¯¢:[/yellow] {args.query}")
        # Need a way to store the last response for single query mode
        last_response_md_single: List[str] = []
        # Run the single query processing within an event loop
        try:
            # ä½¿ç”¨ asyncio.run() æ¥ç®¡ç†äº‹ä»¶å¾ªç¯
            asyncio.run(process_query_async(
                args.query, agent_instance, args.verbose,
                console, last_response_md_single
            ))
            exit_code = 0
        except KeyboardInterrupt:
            console.print("[dim]æ”¶åˆ°ä¸­æ–­ä¿¡å·ã€‚[/dim]")
            exit_code = 1
        except Exception:
            console.print("[bold red]æ‰§è¡Œå•ä¸ªæŸ¥è¯¢æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ã€‚[/bold red]")
            exit_code = 1
        exit(exit_code)

    else:
        # Start interactive loop
        try:
            # ä½¿ç”¨ asyncio.run() æ¥ç®¡ç†äº‹ä»¶å¾ªç¯
            exit_code = asyncio.run(
                run_interactive_cli(agent_instance, args, console)
            )
            exit(exit_code)
        except KeyboardInterrupt:
            console.print("[dim]äº¤äº’å¼ä¼šè¯ä¸­æ–­ã€‚[/dim]")
            exit(1)
        except Exception:
            console.print("[bold red]è¿è¡Œäº¤äº’å¼ CLI æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ã€‚[/bold red]")
            console.print(traceback.format_exc())
            exit(1)


if __name__ == "__main__":
    main()
