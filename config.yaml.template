# DeepSearchAgents Configuration File

# Debug mode (enables verbose output)
debug: false

# Model configuration
models:
  orchestrator_id: "openrouter/openai/gpt-4.1"  # Used for main LLM orchestration
  search_id: "openrouter/openai/gpt-4.1"        # Used for search (only if different)
  reranker_type: "jina-reranker-m0"             # Default reranker type

# Agent common settings
agents:
  common:
    verbose_tool_callbacks: true        # If true, show full tool inputs/outputs
  
  # Settings specific to the ReAct agent
  react:
    max_steps: 25                       # Max number of reasoning steps

  # Settings specific to the CodeAct agent
  codact:
    executor_type: "local"              # local or lambda (for AWS Lambda execution)
    max_steps: 25                       # Max number of steps in execution
    verbosity_level: 1                  # 0=minimal, 1=normal, 2=verbose
    executor_kwargs: {}                 # Additional kwargs for executor
    additional_authorized_imports: []   # Additional Python modules to allow importing

# Service configuration
service:
  host: "0.0.0.0"
  port: 8000
  version: "0.2.3"
  deepsearch_agent_mode: "codact"       # "react" or "codact"

# --- API Keys should remain in .env file ---
# Environment Variable names to look for API Keys (optional, for clarity)
# api_keys:
#   litellm_master_key_var: "LITELLM_MASTER_KEY"
#   serper_api_key_var: "SERPER_API_KEY"
#   jina_api_key_var: "JINA_API_KEY"
#   wolfram_alpha_app_id_var: "WOLFRAM_ALPHA_APP_ID" 

# LiteLLM specific settings (optional)
# litellm:
#   base_url_var: "LITELLM_BASE_URL" # e.g., "YOUR_LITELLM_ENDPOINT_URL" 